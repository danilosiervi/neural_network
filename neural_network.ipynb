{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T22:41:50.301774Z",
     "start_time": "2024-08-10T22:41:50.156700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from enum import Enum\n",
    "from nnfs.datasets import spiral_data\n",
    "import nnfs\n",
    "\n",
    "nnfs.init()"
   ],
   "id": "68f9ae6a982ef0ee",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Neural Network",
   "id": "7f6aecfa1d3a045e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Layers",
   "id": "da3f2530860e9b83"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T22:41:50.781458Z",
     "start_time": "2024-08-10T22:41:50.758162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Activation = Enum('Activation Function', ['linear', 'relu', 'softmax', 'sigmoid'])\n",
    "Optimizer = Enum('Optimizer', ['sgd', 'adagrad', 'rmsprop', 'adam'])\n",
    "Loss = Enum('Loss', ['categorical_crossentropy', 'binary_crossentropy', 'mean_squared_error', 'mean_absolute_error'])"
   ],
   "id": "e345b9ccb2cf1683",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T22:41:50.828085Z",
     "start_time": "2024-08-10T22:41:50.814373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.inputs = np.array([])\n",
    "        self.weights = np.array([])\n",
    "        self.biases = np.array([])\n",
    "        self.outputs = np.array([])\n",
    "        \n",
    "        self.inputs_prime = np.array([])\n",
    "        self.weights_prime = np.array([])\n",
    "        self.biases_prime = np.array([])\n",
    "        self.outputs_prime = np.array([])\n",
    "\n",
    "    def forward(self, inputs: np.ndarray) -> np.ndarray:\n",
    "        pass\n",
    "\n",
    "    def backward(self, outputs_prime: np.ndarray) -> np.ndarray:\n",
    "        pass"
   ],
   "id": "6474afafac8928a5",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Input Layer",
   "id": "24dafbe4cc7a0b82"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T22:41:51.044264Z",
     "start_time": "2024-08-10T22:41:51.026767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class InputLayer(Layer):\n",
    "    def forward(self, inputs: np.ndarray) -> np.ndarray:\n",
    "        self.outputs = inputs\n",
    "        return self.outputs"
   ],
   "id": "a84ad3a8dc1a0584",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dense Layer",
   "id": "fce48a2b2a4ea20b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T22:41:51.090461Z",
     "start_time": "2024-08-10T22:41:51.054243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DenseLayer(Layer):\n",
    "    def __init__(self, input_shape: int, n_neurons: int, activation: str = 'linear', weight_regularizer_l1=0., weight_regularizer_l2=0., bias_regularizer_l1=0., bias_regularizer_l2=0.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.weights = 0.01 * np.random.randn(input_shape, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "        \n",
    "        self.weight_regularizer_l1 = weight_regularizer_l1\n",
    "        self.weight_regularizer_l2 = weight_regularizer_l2\n",
    "        self.bias_regularizer_l1 = bias_regularizer_l1\n",
    "        self.bias_regularizer_l2 = bias_regularizer_l2\n",
    "\n",
    "    def forward(self, inputs: np.ndarray) -> np.ndarray:\n",
    "        self.inputs = inputs\n",
    "        self.outputs = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "        return self.outputs\n",
    "\n",
    "    def backward(self, outputs_prime: np.ndarray) -> np.ndarray:\n",
    "        self.outputs_prime = outputs_prime.copy()\n",
    "        self.weights_prime = np.dot(self.inputs.T, outputs_prime)\n",
    "        self.biases_prime = np.sum(outputs_prime, axis=0, keepdims=True)\n",
    "        \n",
    "        if self.weight_regularizer_l1 > 0:\n",
    "            dl1 = np.ones_like(self.weights)\n",
    "            dl1[self.weights < 0] = -1\n",
    "            self.weights_prime += self.weight_regularizer_l1 * dl1\n",
    "        if self.weight_regularizer_l2 > 0:\n",
    "            self.weights_prime += 2 * self.weight_regularizer_l2 * self.weights\n",
    "\n",
    "        if self.bias_regularizer_l1 > 0:\n",
    "            dl1 = np.ones_like(self.biases)\n",
    "            dl1[self.biases < 0] = -1\n",
    "            self.biases_prime += self.bias_regularizer_l1 * dl1\n",
    "        if self.bias_regularizer_l2 > 0:\n",
    "            self.biases_prime += 2 * self.bias_regularizer_l2 * self.biases\n",
    "\n",
    "        self.inputs_prime = np.dot(outputs_prime, self.weights.T)\n",
    "        return self.inputs_prime"
   ],
   "id": "1c46ecb70ce9cd99",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dropout Layer",
   "id": "578af93a73a06f0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T22:41:51.120996Z",
     "start_time": "2024-08-10T22:41:51.098445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DropoutLayer(Layer):\n",
    "    def __init__(self, rate: float):\n",
    "        super().__init__()\n",
    "        self.binary_mask = np.array([])\n",
    "        self.rate = 1 - rate\n",
    "        \n",
    "    def forward(self, inputs: np.ndarray) -> np.ndarray:\n",
    "        self.inputs = inputs\n",
    "        self.binary_mask = np.random.binomial(1, self.rate, size=inputs.shape) / self.rate\n",
    "        self.outputs = inputs * self.binary_mask\n",
    "        \n",
    "        return self.outputs\n",
    "    \n",
    "    def backward(self, outputs_prime: np.ndarray) -> np.ndarray:\n",
    "        self.outputs_prime = outputs_prime.copy()\n",
    "        self.inputs_prime = outputs_prime * self.binary_mask\n",
    "        \n",
    "        return self.inputs_prime"
   ],
   "id": "385a43773a57ff98",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Activation Function",
   "id": "31f9fbe3f61f613e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T22:41:51.151749Z",
     "start_time": "2024-08-10T22:41:51.129986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ActivationFunction:\n",
    "    def __init__(self, activation_function, activation_function_prime, predictions):\n",
    "        self.inputs = np.array([])\n",
    "        self.outputs = np.array([])\n",
    "        self.inputs_prime = np.array([])\n",
    "        self.outputs_prime = np.array([])\n",
    "        \n",
    "        self.activation_function = activation_function\n",
    "        self.activation_function_prime = activation_function_prime\n",
    "        self.predictions = predictions\n",
    "        \n",
    "    def forward(self, inputs: np.ndarray) -> np.ndarray:\n",
    "        self.inputs = inputs\n",
    "        return self.activation_function(inputs)\n",
    "    \n",
    "    def backward(self, outputs_prime: np.ndarray) -> np.ndarray:\n",
    "        self.outputs_prime = outputs_prime.copy()\n",
    "        return self.activation_function_prime(self.outputs_prime)\n",
    "    \n",
    "    def predictions(self):\n",
    "        return self.predictions(self.outputs)"
   ],
   "id": "7db45f45996608ae",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Linear Function",
   "id": "806399188cc45d4e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T22:41:51.201235Z",
     "start_time": "2024-08-10T22:41:51.189656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ActivationLinear(ActivationFunction):\n",
    "    def __init__(self):\n",
    "        def activation_function(inputs: np.ndarray) -> np.ndarray:\n",
    "            self.outputs = inputs\n",
    "            return self.outputs\n",
    "\n",
    "        def activation_function_prime(outputs_prime: np.ndarray) -> np.ndarray:\n",
    "            self.inputs_prime = outputs_prime\n",
    "            return self.inputs_prime\n",
    "\n",
    "        def predictions(outputs: np.ndarray) -> np.ndarray:\n",
    "            return outputs\n",
    "\n",
    "        super().__init__(activation_function, activation_function_prime, predictions)"
   ],
   "id": "97ea28e35b6b33b7",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Rectified Linear Unit (ReLu) Function",
   "id": "bfc59dd8b7241c75"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T22:41:51.323210Z",
     "start_time": "2024-08-10T22:41:51.313626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ActivationReLU(ActivationFunction):\n",
    "    def __init__(self):\n",
    "        def activation_function(inputs: np.ndarray) -> np.ndarray:\n",
    "            self.outputs = np.maximum(0, inputs)\n",
    "            return self.outputs\n",
    "\n",
    "        def activation_function_prime(outputs_prime: np.ndarray) -> np.ndarray:\n",
    "            self.inputs_prime = outputs_prime.copy()\n",
    "            self.inputs_prime[self.inputs <= 0] = 0\n",
    "\n",
    "            return self.inputs_prime\n",
    "\n",
    "        def predictions(outputs: np.ndarray) -> np.ndarray:\n",
    "            return outputs\n",
    "\n",
    "        super().__init__(activation_function, activation_function_prime, predictions)"
   ],
   "id": "1b1166c2b2005017",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Softmax Function",
   "id": "d38e43c9bacb11e4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T22:41:51.533378Z",
     "start_time": "2024-08-10T22:41:51.517779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ActivationSoftmax(ActivationFunction):\n",
    "    def __init__(self):\n",
    "        def activation_function(inputs: np.ndarray) -> np.ndarray:\n",
    "            exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
    "            self.outputs =  exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "\n",
    "            return self.outputs\n",
    "\n",
    "        def activation_function_prime(outputs_prime: np.ndarray) -> np.ndarray:\n",
    "            self.inputs_prime = np.empty_like(outputs_prime)\n",
    "\n",
    "            for index, (single_output, single_output_prime) in enumerate(zip(self.outputs, outputs_prime)):\n",
    "                single_output = single_output.reshape(-1, 1)\n",
    "                jacobian_matrix = np.diagflat(single_output) - np.dot(single_output, single_output.T)\n",
    "\n",
    "                self.inputs_prime[index] = np.dot(jacobian_matrix, single_output_prime)\n",
    "\n",
    "            return self.inputs_prime\n",
    "        \n",
    "        def predictions(outputs: np.ndarray) -> np.ndarray:\n",
    "            return np.argmax(outputs, axis=1)\n",
    "\n",
    "        super().__init__(activation_function, activation_function_prime, predictions)\n",
    "\n",
    "    def loss_backward(self, outputs_prime, y_true):\n",
    "        samples = len(outputs_prime)\n",
    "\n",
    "        if len(y_true.shape) == 2:\n",
    "            y_true = np.argmax(y_true, axis=1)\n",
    "\n",
    "        self.inputs_prime = outputs_prime.copy()\n",
    "        self.inputs_prime[range(samples), y_true] -= 1\n",
    "        self.inputs_prime /= samples\n",
    "\n",
    "        return self.inputs_prime"
   ],
   "id": "1ea9e31d1827e14d",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Sigmoid Function",
   "id": "906611e0aac0864c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T22:41:51.624319Z",
     "start_time": "2024-08-10T22:41:51.612699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ActivationSigmoid(ActivationFunction):\n",
    "    def __init__(self):\n",
    "        def activation_function(inputs: np.ndarray) -> np.ndarray:\n",
    "            self.outputs = 1 / (1 + np.exp(-inputs))\n",
    "            return self.outputs\n",
    "        \n",
    "        def activation_function_prime(outputs_prime: np.ndarray) -> np.ndarray:\n",
    "            self.inputs_prime = outputs_prime * self.outputs * (1 - self.outputs)\n",
    "            return self.inputs_prime\n",
    "\n",
    "        def predictions(outputs: np.ndarray) -> np.ndarray:\n",
    "            return (outputs > 0.5) * 1\n",
    "\n",
    "        super().__init__(activation_function, activation_function_prime, predictions)"
   ],
   "id": "9d1c459b483536cd",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loss",
   "id": "bef49c56fdb5fd80"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T22:41:51.775869Z",
     "start_time": "2024-08-10T22:41:51.759222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Loss:\n",
    "    def __init__(self):\n",
    "        self.trainable_layers = np.array([])\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        pass\n",
    "    \n",
    "    def backward(self, outputs_prime, y_true):\n",
    "        pass\n",
    "\n",
    "    def calculate(self, y_pred, y_true) -> float:\n",
    "        sample_losses = self.forward(y_pred, y_true)\n",
    "        data_loss = np.mean(sample_losses)\n",
    "        \n",
    "        return data_loss\n",
    "    \n",
    "    def regularization_loss(self, layer) -> float:\n",
    "        regularization_loss = 0.\n",
    "        \n",
    "        for layer in self.trainable_layers:\n",
    "            if layer.weight_regularizer_l1 > 0:\n",
    "                regularization_loss += layer.weight_regularizer_l1 * np.sum(np.abs(layer.weights))\n",
    "            if layer.weight_regularizer_l2 > 0:\n",
    "                regularization_loss += layer.weight_regularizer_l2 * np.sum(layer.weights * layer.weights)\n",
    "    \n",
    "            if layer.bias_regularizer_l1 > 0:\n",
    "                regularization_loss += layer.bias_regularizer_l1 * np.sum(np.abs(layer.biases))\n",
    "            if layer.bias_regularizer_l2 > 0:\n",
    "                regularization_loss += layer.bias_regularizer_l2 * np.sum(layer.biases * layer.biases)\n",
    "    \n",
    "        return regularization_loss\n",
    "    \n",
    "    def remember_trainable_layers(self, trainable_layers: np.ndarray) -> None:\n",
    "        self.trainable_layers = trainable_layers"
   ],
   "id": "259395065414f493",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Categorical Cross-Entropy Loss",
   "id": "7e81c85976d9751c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T22:41:51.798476Z",
     "start_time": "2024-08-10T22:41:51.781870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CategoricalCrossentropy(Loss):\n",
    "    def forward(self, y_pred, y_true) -> np.ndarray:\n",
    "        samples = len(y_pred)\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "        correct_confidences = np.array([])\n",
    "\n",
    "        if len(y_true.shape) == 1:\n",
    "            correct_confidences = y_pred_clipped[\n",
    "                range(samples),\n",
    "                y_true\n",
    "            ]\n",
    "        elif len(y_true.shape) == 2:\n",
    "            correct_confidences = np.sum(\n",
    "                y_pred_clipped * y_true,\n",
    "                axis=1\n",
    "            )\n",
    "\n",
    "        negative_log_likelihoods = -np.log(correct_confidences)\n",
    "        return negative_log_likelihoods\n",
    "\n",
    "    def backward(self, outputs_prime, y_true):\n",
    "        samples = len(outputs_prime)\n",
    "        labels = len(outputs_prime[0])\n",
    "\n",
    "        if len(y_true.shape) == 1:\n",
    "            y_true = np.eye(labels)[y_true]\n",
    "\n",
    "        inputs_prime = (-y_true / outputs_prime) / samples\n",
    "        return inputs_prime"
   ],
   "id": "192b2d02de04fb9f",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Binary Cross-Entropy Loss",
   "id": "26a9e2a7334b4072"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T22:41:51.815293Z",
     "start_time": "2024-08-10T22:41:51.801474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BinaryCrossentropy(Loss):\n",
    "    def forward(self, y_pred, y_true) -> np.ndarray:\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "        sample_losses = -(y_true * np.log(y_pred_clipped) + (1 - y_true) * np.log(1 - y_pred_clipped))\n",
    "        sample_losses = np.mean(sample_losses, axis=1)\n",
    "        \n",
    "        return sample_losses\n",
    "    \n",
    "    def backward(self, outputs_prime, y_true) -> np.ndarray:\n",
    "        samples = len(outputs_prime)\n",
    "        outputs = len(outputs_prime[0])\n",
    "        clipped_outputs_prime = np.clip(outputs_prime, 1e-7, 1 - 1e-7)\n",
    "        \n",
    "        inputs_prime = -(y_true / clipped_outputs_prime - (1 - y_true) / (1 - clipped_outputs_prime)) / outputs\n",
    "        inputs_prime /= samples\n",
    "        \n",
    "        return inputs_prime"
   ],
   "id": "bda24646cc31bde2",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Mean Squared Error Loss",
   "id": "8302accde81738d8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T22:41:51.832275Z",
     "start_time": "2024-08-10T22:41:51.822288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MeanSquaredError(Loss):\n",
    "    def forward(self, y_pred, y_true):\n",
    "        sample_losses = np.mean((y_true - y_pred) ** 2, axis=1)\n",
    "        return sample_losses\n",
    "    \n",
    "    def backward(self, outputs_prime, y_true):\n",
    "        samples = len(outputs_prime)\n",
    "        outputs = len(outputs_prime[0])\n",
    "        \n",
    "        inputs_prime = -2 * (y_true - outputs_prime) / outputs\n",
    "        inputs_prime /= samples\n",
    "        \n",
    "        return inputs_prime"
   ],
   "id": "a081222759a19dcc",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Mean Absolute Error",
   "id": "87ae459d7c60c138"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T22:41:51.849785Z",
     "start_time": "2024-08-10T22:41:51.839379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MeanAbsoluteError(Loss):\n",
    "    def forward(self, y_pred, y_true):\n",
    "        sample_losses = np.mean(np.abs(y_true - y_pred), axis=1)\n",
    "        return sample_losses\n",
    "\n",
    "    def backward(self, outputs_prime, y_true):\n",
    "        samples = len(outputs_prime)\n",
    "        outputs = len(outputs_prime[0])\n",
    "\n",
    "        inputs_prime = np.sign(y_true - outputs_prime) / outputs\n",
    "        inputs_prime /= samples\n",
    "\n",
    "        return inputs_prime"
   ],
   "id": "2d9c77c0807a686a",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Optimizers",
   "id": "59af597caced2024"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Stochastic Gradient Descent (SGD)",
   "id": "ba6a5b09f0e3070f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T22:41:51.869105Z",
     "start_time": "2024-08-10T22:41:51.853788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class OptimizerSGD:\n",
    "    def __init__(self, learning_rate=1., decay=0., momentum=0.):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.momentum = momentum\n",
    "        self.iterations = 0\n",
    "        \n",
    "    def pre_update_params(self):\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate * (1. / (1. + self.decay * self.iterations))\n",
    "        \n",
    "    def update_params(self, layer: Layer):\n",
    "        if self.momentum:\n",
    "            if not hasattr(layer, 'weights_momentum'):\n",
    "                layer.weights_momentum = np.zeros_like(layer.weights)\n",
    "                layer.biases_momentum = np.zeros_like(layer.biases)\n",
    "            \n",
    "            weights_update = self.momentum * layer.weights_momentum - self.current_learning_rate * layer.weights_prime\n",
    "            layer.weights_momentum = weights_update\n",
    "            \n",
    "            biases_update = self.momentum * layer.biases_momentum - self.current_learning_rate * layer.biases_prime\n",
    "            layer.biases_momentum = biases_update\n",
    "        \n",
    "        else:\n",
    "            weights_update = -self.current_learning_rate * layer.weights_prime\n",
    "            biases_update = -self.current_learning_rate * layer.biases_prime\n",
    "            \n",
    "        layer.weights += weights_update\n",
    "        layer.biases += biases_update\n",
    "        \n",
    "    def post_update_params(self):\n",
    "        self.iterations += 1"
   ],
   "id": "382d228ff2d24587",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Adaptative Gradient (AdaGrad)",
   "id": "2fd8864fa9051584"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T22:41:51.918106Z",
     "start_time": "2024-08-10T22:41:51.902021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class OptimizerAdaGrad:\n",
    "    def __init__(self, learning_rate=1., decay=0., epsilon=1e-7):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.epsilon = epsilon\n",
    "        self.iterations = 0\n",
    "\n",
    "    def pre_update_params(self):\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate * (1. / (1. + self.decay * self.iterations))\n",
    "\n",
    "    def update_params(self, layer: Layer):\n",
    "        if not hasattr(layer, 'weights_cache'):\n",
    "            layer.weights_cache = np.zeros_like(layer.weights)\n",
    "            layer.biases_cache = np.zeros_like(layer.biases)\n",
    "\n",
    "        layer.weights_cache += layer.weights_prime ** 2\n",
    "        layer.biases_cache += layer.biases_prime ** 2\n",
    "\n",
    "        layer.weights += -self.current_learning_rate * layer.weights_prime / (np.sqrt(layer.weights_cache) + self.epsilon)\n",
    "        layer.biases += -self.current_learning_rate * layer.biases_prime / (np.sqrt(layer.biases_cache) + self.epsilon)\n",
    "\n",
    "    def post_update_params(self):\n",
    "        self.iterations += 1"
   ],
   "id": "bccd98babdeaa83b",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Root Mean Square Propagation (RMSProp)",
   "id": "53ca0bac1d966405"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T22:41:52.043281Z",
     "start_time": "2024-08-10T22:41:52.030305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class OptimizerRMSProp:\n",
    "    def __init__(self, learning_rate=0.001, decay=0., epsilon=1e-7, rho=0.9):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.epsilon = epsilon\n",
    "        self.rho = rho\n",
    "        self.iterations = 0\n",
    "\n",
    "    def pre_update_params(self):\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate * (1. / (1. + self.decay * self.iterations))\n",
    "\n",
    "    def update_params(self, layer: Layer):\n",
    "        if not hasattr(layer, 'weights_cache'):\n",
    "            layer.weights_cache = np.zeros_like(layer.weights)\n",
    "            layer.biases_cache = np.zeros_like(layer.biases)\n",
    "\n",
    "        layer.weights_cache = self.rho * layer.weights_cache + (1 - self.rho) * layer.weights_prime ** 2\n",
    "        layer.biases_cache = self.rho * layer.biases_cache + (1 - self.rho) * layer.biases_prime ** 2\n",
    "\n",
    "        layer.weights += -self.current_learning_rate * layer.weights_prime / (np.sqrt(layer.weights_cache) + self.epsilon)\n",
    "        layer.biases += -self.current_learning_rate * layer.biases_prime / (np.sqrt(layer.biases_cache) + self.epsilon)\n",
    "\n",
    "    def post_update_params(self):\n",
    "        self.iterations += 1"
   ],
   "id": "850861621ed9d7f2",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Adaptative Momentum (Adam)",
   "id": "b10c9cd6bd7c758c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T22:41:52.197523Z",
     "start_time": "2024-08-10T22:41:52.176538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class OptimizerAdam:\n",
    "    def __init__(self, learning_rate=0.001, decay=0., epsilon=1e-7, beta1=0.9, beta2=0.999):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.iterations = 0\n",
    "        self.epsilon = epsilon\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        \n",
    "    def pre_update_params(self):\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate * (1. / (1. + self.decay * self.iterations))\n",
    "\n",
    "    def update_params(self, layer: Layer):\n",
    "        if not hasattr(layer, 'weights_cache'):\n",
    "            layer.weights_momentum = np.zeros_like(layer.weights)\n",
    "            layer.weights_cache = np.zeros_like(layer.weights)\n",
    "            layer.biases_momentum = np.zeros_like(layer.biases)\n",
    "            layer.biases_cache = np.zeros_like(layer.biases)\n",
    "        \n",
    "        layer.weights_momentum = self.beta1 * layer.weights_momentum + (1 - self.beta1) * layer.weights_prime\n",
    "        layer.biases_momentum = self.beta1 * layer.biases_momentum + (1 - self.beta1) * layer.biases_prime\n",
    "        weights_momentum_corrected = layer.weights_momentum / (1 - self.beta1 ** (self.iterations + 1))\n",
    "        biases_momentum_corrected = layer.biases_momentum / (1 - self.beta1 ** (self.iterations + 1))\n",
    "        \n",
    "        layer.weights_cache = self.beta2 * layer.weights_cache + (1 - self.beta2) * layer.weights_prime ** 2\n",
    "        layer.biases_cache = self.beta2 * layer.biases_cache + (1 - self.beta2) * layer.biases_prime ** 2\n",
    "        weights_cache_corrected = layer.weights_cache / (1 - self.beta2 ** (self.iterations + 1))\n",
    "        biases_cache_corrected = layer.biases_cache / (1 - self.beta2 ** (self.iterations + 1))\n",
    "        \n",
    "        layer.weights += -self.current_learning_rate * weights_momentum_corrected / (np.sqrt(weights_cache_corrected) + self.epsilon)\n",
    "        layer.biases += -self.current_learning_rate * biases_momentum_corrected / (np.sqrt(biases_cache_corrected) + self.epsilon)\n",
    "        \n",
    "    def post_update_params(self):\n",
    "        self.iterations += 1"
   ],
   "id": "1631fae129ac2f42",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T22:41:52.212824Z",
     "start_time": "2024-08-10T22:41:52.202513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Accuracy:\n",
    "    def calculate(self, predictions, y):\n",
    "        comparisons = self.compare(predictions, y)\n",
    "        accuracy = np.mean(comparisons)\n",
    "        return accuracy"
   ],
   "id": "251b76ab776c905f",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model",
   "id": "6b8f41320d3656fb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T22:41:52.241572Z",
     "start_time": "2024-08-10T22:41:52.216818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        self.optimizer = None\n",
    "        self.loss = None\n",
    "        self.input_layer = None\n",
    "        \n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "        \n",
    "    def set(self, *, loss, optimizer):\n",
    "        self.loss = loss\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    def finalize(self):\n",
    "        self.input_layer = InputLayer()\n",
    "        layer_count = len(self.layers)\n",
    "        \n",
    "        for i in range(layer_count):\n",
    "            if i == 0:\n",
    "                self.layers[i].prev = self.input_layer\n",
    "                self.layers[i].next = self.layers[i + 1]\n",
    "                \n",
    "            elif i < layer_count - 1:\n",
    "                self.layers[i].prev = self.layers[i - 1]\n",
    "                self.layers[i].next = self.layers[i + 1]\n",
    "                \n",
    "            else:\n",
    "                self.layers[i].prev = self.layers[i - 1]\n",
    "                self.layers[i].next = self.loss\n",
    "                self.output_layer_activation = self.layers[i]\n",
    "                \n",
    "        if hasattr(self.layers[i], 'weights'):\n",
    "            self.trainable_layers.append(self.layers[i])\n",
    "                \n",
    "    def forward(self, x):\n",
    "        output = self.input_layer.forward(x)\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            output = layer.forward(output)\n",
    "            \n",
    "        return output\n",
    "\n",
    "    def train(self, x, y, *, epochs=10000, print_every=100):\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            output = self.forward(x)\n",
    "            print(output)\n",
    "            exit()"
   ],
   "id": "e91eb273ac920776",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T22:41:52.393089Z",
     "start_time": "2024-08-10T22:41:52.246562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x, y = nnfs.datasets.sine_data()\n",
    "model = NeuralNetwork()\n",
    "\n",
    "model.add(DenseLayer(1, 64))\n",
    "model.add(ActivationReLU())\n",
    "model.add(DenseLayer(64, 64))\n",
    "model.add(ActivationReLU())\n",
    "model.add(DenseLayer(64, 1))\n",
    "model.add(ActivationLinear())\n",
    "\n",
    "model.set(\n",
    "    loss=MeanSquaredError(),\n",
    "    optimizer=OptimizerAdam(learning_rate=0.005, decay=1e-3)\n",
    ")\n",
    "\n",
    "model.finalize()"
   ],
   "id": "42a1dc30eeb2cfbc",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Testing 3",
   "id": "5ee0e918b8b011f7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T22:42:22.361156Z",
     "start_time": "2024-08-10T22:41:52.399076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x, y = nnfs.datasets.sine_data()\n",
    "\n",
    "dense1 = DenseLayer(1, 64)\n",
    "activation1 = ActivationReLU()\n",
    "dense2 = DenseLayer(64, 64)\n",
    "activation2 = ActivationReLU()\n",
    "dense3 = DenseLayer(64, 1)\n",
    "activation3 = ActivationLinear()\n",
    "\n",
    "loss_function = MeanSquaredError()\n",
    "optimizer = OptimizerAdam(learning_rate=0.005, decay=1e-3)\n",
    "accuracy_precision = np.std(y) / 250\n",
    "\n",
    "for epoch in range(10001):\n",
    "    dense1_outputs = dense1.forward(x)\n",
    "    activation1_outputs = activation1.forward(dense1_outputs)\n",
    "    dense2_outputs = dense2.forward(activation1_outputs)\n",
    "    activation2_outputs = activation2.forward(dense2_outputs)\n",
    "    dense3_outputs = dense3.forward(activation2_outputs)\n",
    "    activation3_outputs = activation3.forward(dense3_outputs)\n",
    "    \n",
    "    data_loss = loss_function.calculate(activation3_outputs, y)\n",
    "    regularization_loss = loss_function.regularization_loss(dense1) + loss_function.regularization_loss(dense2) + loss_function.regularization_loss(dense3)\n",
    "    loss = data_loss + regularization_loss\n",
    "    \n",
    "    accuracy = np.mean(np.absolute(activation3_outputs - y) < accuracy_precision)\n",
    "    \n",
    "    if not epoch % 100:\n",
    "        print(f'epoch: {epoch}, '\n",
    "              f'loss: {loss:.3f}, '\n",
    "              f'accuracy: {accuracy:.3f}, '\n",
    "              f'lr: {optimizer.current_learning_rate:.5f}')\n",
    "\n",
    "    loss_outputs = loss_function.backward(activation3_outputs, y)\n",
    "    activation3_inputs_prime = activation3.backward(loss_outputs)\n",
    "    dense3_inputs_prime = dense3.backward(activation3_inputs_prime)\n",
    "    activation2_inputs_prime = activation2.backward(dense3_inputs_prime)\n",
    "    dense2_inputs_prime = dense2.backward(activation2_inputs_prime)\n",
    "    activation1_inputs_prime = activation1.backward(dense2_inputs_prime)\n",
    "    dense1_inputs_prime = dense1.backward(activation1_inputs_prime)\n",
    "    \n",
    "    optimizer.pre_update_params()\n",
    "    optimizer.update_params(dense1)\n",
    "    optimizer.update_params(dense2)\n",
    "    optimizer.update_params(dense3)\n",
    "    optimizer.post_update_params()"
   ],
   "id": "2f1b01ab636f34bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.500, accuracy: 0.002, lr: 0.00500\n",
      "epoch: 100, loss: 0.085, accuracy: 0.005, lr: 0.00455\n",
      "epoch: 200, loss: 0.025, accuracy: 0.023, lr: 0.00417\n",
      "epoch: 300, loss: 0.002, accuracy: 0.038, lr: 0.00385\n",
      "epoch: 400, loss: 0.000, accuracy: 0.486, lr: 0.00357\n",
      "epoch: 500, loss: 0.000, accuracy: 0.570, lr: 0.00334\n",
      "epoch: 600, loss: 0.000, accuracy: 0.564, lr: 0.00313\n",
      "epoch: 700, loss: 0.000, accuracy: 0.750, lr: 0.00294\n",
      "epoch: 800, loss: 0.000, accuracy: 0.784, lr: 0.00278\n",
      "epoch: 900, loss: 0.000, accuracy: 0.799, lr: 0.00263\n",
      "epoch: 1000, loss: 0.000, accuracy: 0.815, lr: 0.00250\n",
      "epoch: 1100, loss: 0.000, accuracy: 0.828, lr: 0.00238\n",
      "epoch: 1200, loss: 0.000, accuracy: 0.839, lr: 0.00227\n",
      "epoch: 1300, loss: 0.000, accuracy: 0.804, lr: 0.00217\n",
      "epoch: 1400, loss: 0.000, accuracy: 0.857, lr: 0.00208\n",
      "epoch: 1500, loss: 0.000, accuracy: 0.108, lr: 0.00200\n",
      "epoch: 1600, loss: 0.000, accuracy: 0.872, lr: 0.00192\n",
      "epoch: 1700, loss: 0.000, accuracy: 0.880, lr: 0.00185\n",
      "epoch: 1800, loss: 0.000, accuracy: 0.887, lr: 0.00179\n",
      "epoch: 1900, loss: 0.000, accuracy: 0.895, lr: 0.00172\n",
      "epoch: 2000, loss: 0.000, accuracy: 0.900, lr: 0.00167\n",
      "epoch: 2100, loss: 0.000, accuracy: 0.915, lr: 0.00161\n",
      "epoch: 2200, loss: 0.000, accuracy: 0.920, lr: 0.00156\n",
      "epoch: 2300, loss: 0.000, accuracy: 0.773, lr: 0.00152\n",
      "epoch: 2400, loss: 0.000, accuracy: 0.926, lr: 0.00147\n",
      "epoch: 2500, loss: 0.000, accuracy: 0.932, lr: 0.00143\n",
      "epoch: 2600, loss: 0.000, accuracy: 0.932, lr: 0.00139\n",
      "epoch: 2700, loss: 0.000, accuracy: 0.937, lr: 0.00135\n",
      "epoch: 2800, loss: 0.000, accuracy: 0.480, lr: 0.00132\n",
      "epoch: 2900, loss: 0.000, accuracy: 0.941, lr: 0.00128\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[73], line 22\u001B[0m\n\u001B[0;32m     19\u001B[0m dense3_outputs \u001B[38;5;241m=\u001B[39m dense3\u001B[38;5;241m.\u001B[39mforward(activation2_outputs)\n\u001B[0;32m     20\u001B[0m activation3_outputs \u001B[38;5;241m=\u001B[39m activation3\u001B[38;5;241m.\u001B[39mforward(dense3_outputs)\n\u001B[1;32m---> 22\u001B[0m data_loss \u001B[38;5;241m=\u001B[39m loss_function\u001B[38;5;241m.\u001B[39mcalculate(activation3_outputs, y)\n\u001B[0;32m     23\u001B[0m regularization_loss \u001B[38;5;241m=\u001B[39m loss_function\u001B[38;5;241m.\u001B[39mregularization_loss(dense1) \u001B[38;5;241m+\u001B[39m loss_function\u001B[38;5;241m.\u001B[39mregularization_loss(dense2) \u001B[38;5;241m+\u001B[39m loss_function\u001B[38;5;241m.\u001B[39mregularization_loss(dense3)\n\u001B[0;32m     24\u001B[0m loss \u001B[38;5;241m=\u001B[39m data_loss \u001B[38;5;241m+\u001B[39m regularization_loss\n",
      "Cell \u001B[1;32mIn[61], line 12\u001B[0m, in \u001B[0;36mLoss.calculate\u001B[1;34m(self, y_pred, y_true)\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcalculate\u001B[39m(\u001B[38;5;28mself\u001B[39m, y_pred, y_true) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mfloat\u001B[39m:\n\u001B[1;32m---> 12\u001B[0m     sample_losses \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward(y_pred, y_true)\n\u001B[0;32m     13\u001B[0m     data_loss \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmean(sample_losses)\n\u001B[0;32m     15\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m data_loss\n",
      "Cell \u001B[1;32mIn[64], line 3\u001B[0m, in \u001B[0;36mMeanSquaredError.forward\u001B[1;34m(self, y_pred, y_true)\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, y_pred, y_true):\n\u001B[1;32m----> 3\u001B[0m     sample_losses \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmean((y_true \u001B[38;5;241m-\u001B[39m y_pred) \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m2\u001B[39m, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m sample_losses\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504\u001B[0m, in \u001B[0;36mmean\u001B[1;34m(a, axis, dtype, out, keepdims, where)\u001B[0m\n\u001B[0;32m   3501\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   3502\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m mean(axis\u001B[38;5;241m=\u001B[39maxis, dtype\u001B[38;5;241m=\u001B[39mdtype, out\u001B[38;5;241m=\u001B[39mout, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m-> 3504\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _methods\u001B[38;5;241m.\u001B[39m_mean(a, axis\u001B[38;5;241m=\u001B[39maxis, dtype\u001B[38;5;241m=\u001B[39mdtype,\n\u001B[0;32m   3505\u001B[0m                       out\u001B[38;5;241m=\u001B[39mout, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:121\u001B[0m, in \u001B[0;36m_mean\u001B[1;34m(a, axis, dtype, out, keepdims, where)\u001B[0m\n\u001B[0;32m    119\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(ret, mu\u001B[38;5;241m.\u001B[39mndarray):\n\u001B[0;32m    120\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m _no_nep50_warning():\n\u001B[1;32m--> 121\u001B[0m         ret \u001B[38;5;241m=\u001B[39m um\u001B[38;5;241m.\u001B[39mtrue_divide(\n\u001B[0;32m    122\u001B[0m                 ret, rcount, out\u001B[38;5;241m=\u001B[39mret, casting\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124munsafe\u001B[39m\u001B[38;5;124m'\u001B[39m, subok\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m    123\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_float16_result \u001B[38;5;129;01mand\u001B[39;00m out \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    124\u001B[0m         ret \u001B[38;5;241m=\u001B[39m arr\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mtype(ret)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T22:42:25.000171Z",
     "start_time": "2024-08-10T22:42:24.547364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_test, y_test = nnfs.datasets.sine_data()\n",
    "\n",
    "dense1_outputs = dense1.forward(x_test)\n",
    "activation1_outputs = activation1.forward(dense1_outputs)\n",
    "dense2_outputs = dense2.forward(activation1_outputs)\n",
    "activation2_outputs = activation2.forward(dense2_outputs)\n",
    "dense3_outputs = dense3.forward(activation2_outputs)\n",
    "activation3_outputs = activation3.forward(dense3_outputs)\n",
    "\n",
    "plt.plot(x_test, activation3_outputs)\n",
    "plt.show()"
   ],
   "id": "900342d5254bc04b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T22:42:22.369139Z",
     "start_time": "2024-08-10T22:42:22.368143Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "4f0be0f6cb5b1c39",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
